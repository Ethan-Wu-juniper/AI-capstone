{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Public Image Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcDLCbmZkh4c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms, datasets\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from torch.utils.data import random_split, DataLoader, SubsetRandomSampler, ConcatDataset\n",
        "from sklearn.metrics import *\n",
        "import pandas as pd\n",
        "import seaborn as sb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvwN9qihK-5y"
      },
      "source": [
        "### Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ei4V8a3ALBFx"
      },
      "outputs": [],
      "source": [
        "LR = 0.0001 # learning rate\n",
        "TRANS = transforms.Compose([transforms.Resize((224,224)),transforms.ToTensor()])\n",
        "use_gpu = torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ycfuQdOKh5C"
      },
      "source": [
        "### Data input & preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7_-lR3Nttza",
        "outputId": "d51f5a0e-3b9d-4006-e17f-cdbb611cd5b6"
      },
      "outputs": [],
      "source": [
        "data = datasets.ImageFolder('drive/MyDrive/weather',transform=TRANS)\n",
        "print(data.class_to_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz1CVnxONeZY"
      },
      "source": [
        "### Model Construct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9dk1I8_Ngrh"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.Conv2d(3,16,5,1,2),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2)\n",
        "    )\n",
        "    self.conv2 = nn.Sequential(\n",
        "        nn.Conv2d(16,32,5,1,2),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2)\n",
        "    )\n",
        "    self.out = nn.Linear(32*56*56,4)\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = x.view(x.size(0),-1)\n",
        "    output = self.out(x)\n",
        "    return output\n",
        "\n",
        "def reset_weights(m):\n",
        "  if hasattr(m,'reset_parameters'):\n",
        "    m.reset_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pihZ2W4ZNdJ"
      },
      "source": [
        "### Function Define"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0A8fGCdoLnG3"
      },
      "outputs": [],
      "source": [
        "def ML(cnn,data,EPOCH,BATCH,log):\n",
        "  kfold = KFold(n_splits=3,shuffle=True)\n",
        "  optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\n",
        "  loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "  acc = 0\n",
        "  rec = [0,0,0,0]\n",
        "  prec = [0,0,0,0]\n",
        "  f1 = [0,0,0,0]\n",
        "  matrix = np.zeros((4,4)).tolist()\n",
        "\n",
        "  for fold, (train_idx, test_idx) in enumerate(kfold.split(data)):\n",
        "    cnn.apply(reset_weights)\n",
        "    if log == 1:\n",
        "      print('-------Fold :',fold,'start--------')\n",
        "    train_subset = SubsetRandomSampler(train_idx)\n",
        "    test_subset = SubsetRandomSampler(test_idx)\n",
        "\n",
        "    train_data = DataLoader(data,batch_size=BATCH,sampler=train_subset)\n",
        "    test_data = DataLoader(data,batch_size=1,sampler=test_subset)\n",
        "\n",
        "    for epoch in range(EPOCH):\n",
        "      if log == 1:\n",
        "        print('-- Epoch :',epoch,'--')\n",
        "      for i, (x,y) in enumerate(train_data):\n",
        "        output = cnn(x)\n",
        "        loss = loss_func(output, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    pred_y = []\n",
        "    real_y = []\n",
        "    for x,y in test_data:\n",
        "      valid_output = cnn(x)\n",
        "      pred_y.append(torch.max(valid_output,1)[1].data.numpy().squeeze().tolist())\n",
        "      real_y.append(y[0].tolist())\n",
        "    acc += accuracy_score(real_y,pred_y)\n",
        "    rec += recall_score(real_y,pred_y,average=None)\n",
        "    prec += precision_score(real_y,pred_y,average=None)\n",
        "    f1 += f1_score(real_y,pred_y,average=None)\n",
        "    matrix += confusion_matrix(real_y,pred_y)\n",
        "  acc /= 3\n",
        "  rec /= 3\n",
        "  prec /= 3\n",
        "  f1 /= 3\n",
        "  matrix /= 3\n",
        "  matrix = matrix.tolist()\n",
        "  scores = [acc,rec,prec,f1]\n",
        "\n",
        "  for i in matrix:\n",
        "    for j in range(len(i)):\n",
        "      i[j] = round(i[j])\n",
        "  if log == 1:\n",
        "    print('------------ end -------------')\n",
        "  return scores, matrix\n",
        "\n",
        "def testing(test_data,cnn):\n",
        "  test_data = DataLoader(test_data,batch_size=1)\n",
        "  pred_y = []\n",
        "  real_y = []\n",
        "  # print(len(test_data))\n",
        "  for x,y in test_data:\n",
        "    # print(x,y)\n",
        "    valid_output = cnn(x)\n",
        "    pred_y.append(torch.max(valid_output,1)[1].data.numpy().squeeze().tolist())\n",
        "    real_y.append(y[0].tolist())\n",
        "  # print(pred_y)\n",
        "  # print(real_y)\n",
        "  acc = accuracy_score(real_y,pred_y)\n",
        "  rec = recall_score(real_y,pred_y,average=None)\n",
        "  prec = precision_score(real_y,pred_y,average=None)\n",
        "  f1 = f1_score(real_y,pred_y,average=None)\n",
        "  matrix = confusion_matrix(real_y,pred_y)\n",
        "  matrix = matrix.tolist()\n",
        "  scores = [acc,rec,prec,f1]\n",
        "\n",
        "  # for i in matrix:\n",
        "  #   for j in range(len(i)):\n",
        "  #     i[j] = round(i[j])\n",
        "  return scores, matrix\n",
        "\n",
        "def result(data,scores,matrix):\n",
        "  print('accrucy score :',scores[0])\n",
        "\n",
        "  form = pd.DataFrame(scores[1:],columns=[i for i in data.class_to_idx],index=['recall score','precision score','f1 score'])\n",
        "  display(form)\n",
        "\n",
        "  form = pd.DataFrame(matrix,data.class_to_idx,data.class_to_idx)\n",
        "  sb.heatmap(form,annot=True,fmt='d',linewidth=5,cmap='YlGnBu')\n",
        "  plt.xlabel('predicted')\n",
        "  plt.ylabel('real')\n",
        "  plt.title('confusion matrix')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OQzGeviPxnh"
      },
      "source": [
        "### Training with different hyper-parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "LTevgWbpvkVf",
        "outputId": "db99f758-6930-48ec-edde-9a35419dd6c0"
      },
      "outputs": [],
      "source": [
        "cnn = CNN()\n",
        "\n",
        "scores, matrix = ML(cnn,data,1,64,0)\n",
        "result(data,scores,matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "id": "8fyYWIkZvqyw",
        "outputId": "a67aebf8-9643-4142-8390-be368dd9266c"
      },
      "outputs": [],
      "source": [
        "cnn = CNN()\n",
        "\n",
        "scores, matrix = ML(cnn,data,5,64,0)\n",
        "result(data,scores,matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "Cmap6z8swZRO",
        "outputId": "127c5772-b5a6-44b3-aa05-44cb30bd0e76"
      },
      "outputs": [],
      "source": [
        "cnn = CNN()\n",
        "\n",
        "scores, matrix = ML(cnn,data,20,64,0)\n",
        "result(data,scores,matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "eJ5B6QGvvtz3",
        "outputId": "c10a56b8-ebdf-4f32-aa07-448bb5ebae08"
      },
      "outputs": [],
      "source": [
        "cnn = CNN()\n",
        "\n",
        "scores, matrix = ML(cnn,data,5,8,0)\n",
        "result(data,scores,matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "bwhoEnwLvvtP",
        "outputId": "5dbe4870-6f6f-4d02-b8e4-15cfe81ddc1a"
      },
      "outputs": [],
      "source": [
        "cnn = CNN()\n",
        "\n",
        "scores, matrix = ML(cnn,data,5,256,0)\n",
        "result(data,scores,matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6HnpgMtP9dx"
      },
      "source": [
        "### Data Augmentation (flip)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1IIq6VzQCGU"
      },
      "outputs": [],
      "source": [
        "FLIP = transforms.Compose([transforms.RandomHorizontalFlip(p=1),transforms.Resize((224,224)),transforms.ToTensor()])\n",
        "flip_data = datasets.ImageFolder('drive/MyDrive/weather',transform=FLIP)\n",
        "\n",
        "flip_data = ConcatDataset([data,flip_data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 880
        },
        "id": "CciQAmJnS7WJ",
        "outputId": "a71dbb24-68c9-4c04-f4ed-197087b6db8c"
      },
      "outputs": [],
      "source": [
        "cnn = CNN()\n",
        "\n",
        "scores, matrix = ML(cnn,flip_data,20,64,0)\n",
        "result(data,scores,matrix)\n",
        "\n",
        "print('--- testing ---')\n",
        "scores, matrix = testing(data,cnn)\n",
        "result(data,scores,matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "gJ7zbIzSn4gm",
        "outputId": "035a0062-f764-4e86-cd67-99dfe9a122f1"
      },
      "outputs": [],
      "source": [
        "scores, matrix = testing(data,cnn)\n",
        "result(data,scores,matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87cNOE3ttvhE"
      },
      "source": [
        "### Data Augmentation (a variety of methods)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJvlSipSVexj"
      },
      "outputs": [],
      "source": [
        "AUG = [transforms.RandomHorizontalFlip(p=1),\n",
        "    transforms.RandomCrop(size=300,pad_if_needed=True),\n",
        "    transforms.ColorJitter(brightness=0.5,contrast=0,saturation=0,hue=0),\n",
        "    transforms.ColorJitter(brightness=0,contrast=0.5,saturation=0,hue=0),\n",
        "    transforms.ColorJitter(brightness=0,contrast=0,saturation=0.5,hue=0),\n",
        "    transforms.ColorJitter(brightness=0,contrast=0,saturation=0,hue=0.5),\n",
        "    transforms.RandomRotation(degrees=5,expand=False,fill=None)]\n",
        "\n",
        "big_data = data\n",
        "for i in range(len(AUG)):\n",
        "  BIG = transforms.Compose([AUG[i],transforms.Resize((224,224)),transforms.ToTensor()])\n",
        "  aug_data = datasets.ImageFolder('drive/MyDrive/weather',transform=BIG)\n",
        "\n",
        "  big_data = ConcatDataset([aug_data,big_data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iq061wyVe_4"
      },
      "outputs": [],
      "source": [
        "cnn = CNN()\n",
        "\n",
        "scores, matrix = ML(cnn,big_data,20,64,0)\n",
        "result(data,scores,matrix)\n",
        "\n",
        "print('--- testing ---')\n",
        "scores, matrix = testing(data,cnn)\n",
        "result(data,scores,matrix)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "AI project1 (CNN).ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
